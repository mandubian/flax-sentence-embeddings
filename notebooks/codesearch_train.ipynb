{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('flax-sentence-embeddings-zVHyP_u9-py3.9': venv)"
  },
  "interpreter": {
   "hash": "4fefb6681ffd05f7a8a0fc21cb824f16da8a96bee455cd07578e426e280af9a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import wandb\n",
    "import json\n",
    "import os\n",
    "\n",
    "# for training script\n",
    "from dataclasses import dataclass, field, asdict, replace\n",
    "from functools import partial\n",
    "from typing import Callable, List, Union\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import jax_utils, struct, traverse_util\n",
    "from flax.training import train_state\n",
    "from flax.serialization import to_bytes, from_bytes\n",
    "from flax.training.common_utils import shard\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from trainer.loss.custom import multiple_negatives_ranking_loss\n",
    "\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, FlaxAutoModel\n",
    "import datasets\n",
    "\n",
    "\n",
    "from trainer.utils.ops import normalize_L2, mean_pooling, cos_sim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingArgs:\n",
    "    model_id: str = \"microsoft/codebert-base\"\n",
    "    max_epochs: int = 20\n",
    "    batch_size_per_device: int = 32\n",
    "    seed: int = 42\n",
    "    lr: float = 2e-5\n",
    "    init_lr: float = 1e-5\n",
    "    warmup_steps: int = 2000\n",
    "    weight_decay: float = 1e-3\n",
    "\n",
    "    input1_maxlen: int = 200\n",
    "    input2_maxlen: int = 200\n",
    "    \n",
    "    logging_steps: int = 20\n",
    "    save_dir: str = \"checkpoints\"\n",
    "    save_dir_exp: str = \"checkpoints\"\n",
    "\n",
    "    tr_data_files: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"tr.csv\",\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    val_data_files: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"val.csv\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.batch_size = self.batch_size_per_device * jax.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    loss_fn: Callable = struct.field(pytree_node=False)\n",
    "    scheduler_fn: Callable = struct.field(pytree_node=False)\n",
    "    acc_fn: Callable = struct.field(pytree_node=False)\n",
    "\n",
    "\n",
    "def warmup_and_constant(lr, init_lr, warmup_steps):\n",
    "    warmup_fn = optax.linear_schedule(init_value=init_lr, end_value=lr, transition_steps=warmup_steps)\n",
    "    constant_fn = optax.constant_schedule(value=lr)\n",
    "    lr = optax.join_schedules(schedules=[warmup_fn, constant_fn], boundaries=[warmup_steps])\n",
    "    return lr\n",
    "\n",
    "def build_tx(lr, init_lr, warmup_steps, weight_decay):\n",
    "    def weight_decay_mask(params):\n",
    "        params = traverse_util.flatten_dict(params)\n",
    "        mask = {k: (v[-1] != \"bias\" and v[-2:] != (\"LayerNorm\", \"scale\")) for k, v in params.items()}\n",
    "        return traverse_util.unflatten_dict(mask)\n",
    "    lr = warmup_and_constant(lr, init_lr, warmup_steps)\n",
    "    tx = optax.adamw(learning_rate=lr, weight_decay=weight_decay, mask=weight_decay_mask)\n",
    "    return tx, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def batch_accuracy(embeddings_a: jnp.DeviceArray, embeddings_b: jnp.DeviceArray,\n",
    "                   similarity_fct=cos_sim):\n",
    "    \"\"\"\n",
    "\n",
    "    :param embeddings_a:\n",
    "    :param embeddings_b: if passing additional hard negatives, use jnp.concatenate([positives, negatives], axis=0) as input.\n",
    "    :param similarity_fct:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert (len(embeddings_a) <= len(embeddings_b))\n",
    "    scores = similarity_fct(embeddings_a, embeddings_b)\n",
    "    assert scores.shape == (len(embeddings_a), len(embeddings_b))\n",
    "\n",
    "    indices = np.argmax(scores, axis=1)\n",
    "\n",
    "    labels = jnp.arange(len(scores), dtype=jnp.int32)\n",
    "\n",
    "    return np.sum(indices == labels)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def train_step(state, model_input1, model_input2, drp_rng):\n",
    "    train = True\n",
    "    new_drp_rng, drp_rng = jax.random.split(drp_rng, 2)\n",
    "\n",
    "    def loss_fn(params, model_input1, model_input2, drp_rng):\n",
    "        def _forward(model_input):\n",
    "            attention_mask = model_input[\"attention_mask\"]\n",
    "            model_output = state.apply_fn(**model_input, params=params, train=train, dropout_rng=drp_rng)\n",
    "\n",
    "            embedding = mean_pooling(model_output, attention_mask)\n",
    "            embedding = normalize_L2(embedding)\n",
    "\n",
    "            # gather all the embeddings on same device for calculation loss over global batch\n",
    "            embedding = jax.lax.all_gather(embedding, axis_name=\"batch\")\n",
    "            embedding = jnp.reshape(embedding, (-1, embedding.shape[-1]))\n",
    "\n",
    "            return embedding\n",
    "\n",
    "        embedding1, embedding2 = _forward(model_input1), _forward(model_input2)\n",
    "        return state.loss_fn(embedding1, embedding2)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params, model_input1, model_input2, drp_rng)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    step = jax.lax.pmean(state.step, axis_name=\"batch\")\n",
    "    metrics = {\"train_loss\": loss, \"lr\": state.scheduler_fn(step)}\n",
    "\n",
    "    return state, metrics, new_drp_rng\n",
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def val_step(state, model_inputs1, model_inputs2):\n",
    "    train = False\n",
    "\n",
    "    def _forward(model_input):\n",
    "        attention_mask = model_input[\"attention_mask\"][..., None]\n",
    "        embedding = state.apply_fn(**model_input, params=state.params, train=train)[0]\n",
    "        attention_mask = jnp.broadcast_to(attention_mask, jnp.shape(embedding))\n",
    "\n",
    "        embedding = embedding * attention_mask\n",
    "        embedding = jnp.mean(embedding, axis=1)\n",
    "\n",
    "        modulus = jnp.sum(jnp.square(embedding), axis=-1, keepdims=True)\n",
    "        embedding = embedding / jnp.maximum(modulus, 1e-12)\n",
    "\n",
    "        # gather all the embeddings on same device for calculation loss over global batch\n",
    "        embedding = jax.lax.all_gather(embedding, axis_name=\"batch\")\n",
    "        embedding = jnp.reshape(embedding, (-1, embedding.shape[-1]))\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    embedding1, embedding2 = _forward(model_inputs1), _forward(model_inputs2)\n",
    "    loss = state.loss_fn(embedding1, embedding2)\n",
    "    acc = state.acc_fn(embedding1, embedding2)    \n",
    "    return jnp.mean(loss), jnp.sum(acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_batched_dataset(dataset, batch_size, seed=None):\n",
    "    if seed is not None:\n",
    "        dataset = dataset.shuffle(seed=seed)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i*batch_size: (i+1)*batch_size]\n",
    "        yield dict(batch)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    tokenizer: Union[PreTrainedTokenizerFast, PreTrainedTokenizer]\n",
    "    input1_maxlen: int = 128\n",
    "    input2_maxlen: int = 128\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # Currently only static padding; TODO: change below for adding dynamic padding support\n",
    "        model_input1 = self.tokenizer(batch[\"docstring\"], return_tensors=\"jax\", max_length=self.input1_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input2 = self.tokenizer(batch[\"code\"], return_tensors=\"jax\", max_length=self.input2_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input1, model_input2 = dict(model_input1), dict(model_input2)\n",
    "        return shard(model_input1), shard(model_input2)\n",
    "\n",
    "\n",
    "def save_checkpoint(save_dir, state, save_fn=None, training_args=None):\n",
    "    print(f\"saving checkpoint in {save_dir}\", end=\" ... \")\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    state = jax_utils.unreplicate(state)\n",
    "\n",
    "    if save_fn is not None:\n",
    "        # saving model in HF fashion\n",
    "        save_fn(save_dir, params=state.params)\n",
    "    else:\n",
    "        path = os.path.join(save_dir, \"flax_model.msgpack\")\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(to_bytes(state.params))\n",
    "\n",
    "    # this will save optimizer states\n",
    "    path = os.path.join(save_dir, \"opt_state.msgpack\")\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(to_bytes(state.opt_state))\n",
    "\n",
    "    if training_args is not None:\n",
    "        path = os.path.join(save_dir, \"training_args.json\")\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(asdict(training_args), f)\n",
    "\n",
    "    print(\"done!!\")\n",
    "\n",
    "\n",
    "def prepare_dataset(args):\n",
    "    # tr_dataset = load_dataset(\"csv\", data_files=args.tr_data_files, split=\"train\")\n",
    "    # val_dataset = load_dataset(\"csv\", data_files=args.val_data_files, split=\"val\")\n",
    "    dataset = datasets.load_dataset(\"csv\", data_files={\n",
    "      \"train\": \"../data/codesearchnet_train.csv.gz\",\n",
    "      \"test\": \"../data/codesearchnet_test.csv.gz\",\n",
    "      \"validation\": \"../data/codesearchnet_validation.csv.gz\"\n",
    "    })\n",
    "\n",
    "    # columns_to_remove = ['repo', 'path', 'func_name', 'original_string', 'sha', 'url', 'partition']\n",
    "    # dataset = dataset.remove_columns(columns_to_remove)\n",
    "\n",
    "    # drop extra batch from the end\n",
    "    for split in dataset:\n",
    "        num_samples = len(dataset[split]) - len(dataset[split]) % args.batch_size\n",
    "        dataset[split] = dataset[split].shuffle(seed=args.seed).select(range(num_samples))\n",
    "\n",
    "    tr_dataset, val_dataset = dataset[\"train\"], dataset[\"validation\"]\n",
    "    return tr_dataset, val_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:i10jgnf7) before initializing another..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "...Successfully finished last run (ID:i10jgnf7). Initializing new run:<br/><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.33<br/>\n                Syncing run <strong style=\"color:#cdcd00\">proud-tree-25</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/mandubian/code-search-net\" target=\"_blank\">https://wandb.ai/mandubian/code-search-net</a><br/>\n                Run page: <a href=\"https://wandb.ai/mandubian/code-search-net/runs/1xeeta0r\" target=\"_blank\">https://wandb.ai/mandubian/code-search-net/runs/1xeeta0r</a><br/>\n                Run data is saved locally in <code>/home/pascal_voitot/flax-sentence-embeddings/notebooks/wandb/run-20210708_103507-1xeeta0r</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TrainingArgs(model_id='microsoft/codebert-base', max_epochs=20, batch_size_per_device=32, seed=42, lr=2e-05, init_lr=1e-05, warmup_steps=2000, weight_decay=0.001, input1_maxlen=200, input2_maxlen=200, logging_steps=20, save_dir='checkpoints', save_dir_exp='checkpoints-1xeeta0r', tr_data_files=['tr.csv'], val_data_files=['val.csv'])\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArgs()\n",
    "\n",
    "logger = wandb.init(project=\"code-search-net\", config=asdict(args))\n",
    "\n",
    "logging_dict = dict(logger.config); logging_dict[\"save_dir_exp\"] = f\"{logging_dict['save_dir']}-{logger.id}\"\n",
    "args = replace(args, **logging_dict)\n",
    "\n",
    "print(args)\n",
    "#main(args, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FlaxAutoModel.from_pretrained(args.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    input1_maxlen=args.input1_maxlen,\n",
    "    input2_maxlen=args.input2_maxlen,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_args = {\n",
    "    \"lr\": args.lr,\n",
    "    \"init_lr\": args.init_lr,\n",
    "    \"warmup_steps\": args.warmup_steps,\n",
    "    \"weight_decay\": args.weight_decay,\n",
    "}\n",
    "tx, lr = build_tx(**tx_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/pascal_voitot/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/lib/xla_bridge.py:382: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n  warnings.warn(\n/home/pascal_voitot/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/lib/xla_bridge.py:369: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=tx,\n",
    "    loss_fn=multiple_negatives_ranking_loss,\n",
    "    scheduler_fn=lr,\n",
    "    acc_fn=batch_accuracy\n",
    ")\n",
    "state = jax_utils.replicate(state)\n",
    "\n",
    "rng = jax.random.PRNGKey(args.seed)\n",
    "drp_rng = jax.random.split(rng, jax.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-83af4b22d0d2ded6\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23)\n",
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-d4b0dc892085490c.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-09baa20efd3007e5.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-9d2d039304561328.arrow\n"
     ]
    }
   ],
   "source": [
    "tr_dataset, val_dataset = prepare_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, dataset, logger, args, drp_rng):\n",
    "    # training step\n",
    "    total = len(tr_dataset) // args.batch_size\n",
    "    batch_iterator = get_batched_dataset(dataset, args.batch_size, seed=epoch)\n",
    "    for i, batch in tqdm(enumerate(batch_iterator), desc=f\"Running epoch-{epoch}\", total=total):\n",
    "        model_input1, model_input2 = data_collator(batch)\n",
    "        state, metrics, drp_rng = train_step(state, model_input1, model_input2, drp_rng)\n",
    "\n",
    "        #print(\"metrics\", metrics)\n",
    "        if (i + 1) % args.logging_steps == 0:\n",
    "            train_loss = jax_utils.unreplicate(metrics[\"train_loss\"]).item()\n",
    "            # tqdm.write(str(dict(train_loss=train_loss, step=i+1)))\n",
    "            logger.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"step\": i + 1,\n",
    "            }, commit=True)\n",
    "\n",
    "    return state, drp_rng\n",
    "\n",
    "def eval_epoch(state, val_dataset, logger, args, best_acc):\n",
    "    # evaluation\n",
    "    val_loss  = jnp.array(0.)\n",
    "    val_acc  = jnp.array(0.)\n",
    "    total = len(val_dataset) // args.batch_size\n",
    "    val_batch_iterator = get_batched_dataset(val_dataset, args.batch_size, seed=None)\n",
    "    for j, batch in tqdm(enumerate(val_batch_iterator), desc=f\"Eval after epoch-{epoch}\", total=total):\n",
    "       model_input1, model_input2 = data_collator(batch)\n",
    "       val_step_loss, val_step_acc = val_step(state, model_input1, model_input2)\n",
    "       val_loss += jax_utils.unreplicate(val_step_loss)\n",
    "       val_acc += jax_utils.unreplicate(val_step_acc)\n",
    "\n",
    "    val_loss = val_loss.item() / (j + 1)\n",
    "    val_acc = val_acc.item() / len(val_dataset)\n",
    "    logger.log({\"val_loss\": val_loss, \"val_acc\": val_acc}, commit=True)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        save_dir = os.path.join(args.save_dir, args.save_dir_exp, args.save_dir_exp + f\"-epoch-{epoch}\")\n",
    "        save_checkpoint(save_dir, state, save_fn=model.save_pretrained, training_args=args)\n",
    "\n",
    "        return val_acc\n",
    "    \n",
    "    return best_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-0:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80f9122cffe0406392878f5d49022061"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saving checkpoint in checkpoints/checkpoints-1xeeta0r/checkpoints-1xeeta0r-epoch-0 ... done!!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-0:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "800ae8e47aef4c7fb94ef2b6682beff4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-93f4283e5294b729.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-0:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "653df3989a07415caa8cade4065ff670"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saving checkpoint in checkpoints/checkpoints-1xeeta0r/checkpoints-1xeeta0r-epoch-0 ... done!!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-1:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ab2e523a243495f9a260a78197d6dd4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-3ead92aa22036b87.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-1:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f601acfd0ac14ad9aa4915924a994c8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-2:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "263b6b15dfcc4cfcb434d720dac45711"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-83f75a01d2a45927.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-2:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35032143e6ef4806b2367e4090f763ea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-3:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f03de83262a448b1b9a113860ae5df66"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-da29affa21823c68.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-3:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e95e1d71871425a9fd6454563d761d8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-4:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2616cdd09bdc438283b0b09b4b388372"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-14fd64301bac676a.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-4:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3625d8bdc0f4702bfcf3ef86df2b883"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-5:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9aeb01f9aa0543abb63b8e331b0ae5b7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-a4e61e21d828d04d.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-5:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d0040c63d2e4309955963a810b7ba2d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-6:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e237497e75084f3cb70f4bc3e38787ff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-805e5890dac6d560.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-6:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ff48b38f4da407693046d34290b5456"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-7:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49b96b69de764a96833e26384759360f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-27fb9d340ea7ee4d.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-7:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e72df12e04b4113abd83dff0d97d63d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-8:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61819983d2654a4ca4752bae86e0ce2c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-5472cd5ce256783b.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-8:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4aaeb71780641788ec78ee4a7ea409a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-9:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3334458c31948b580d6496d170a64a3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-5a877503d05610e6.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-9:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e34bc9eddadf46b78673d2506e30f291"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-10:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "565a843adccc4ee58a046bc0907b7629"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-3c9d2753438c4106.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-10:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "558bf2013c1648f4a0b3dc2d1648112b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-11:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "894f38bcec554e0ab2a92079170173e7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-e92d86c5bd52dc6e.arrow\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Eval after epoch-11:   0%|          | 0/122 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0735ef09133d4006acdb5a9e811a3652"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-12:   0%|          | 0/2664 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "442c220fbafb45638ae1bd4324b30929"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-2ce0ae2355203fa1.arrow\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158295/2577326203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrp_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrp_rng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_158295/2005822386.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(state, dataset, logger, args, drp_rng)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Running epoch-{epoch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrp_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrp_rng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(\"metrics\", metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mf_pmapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m                                                   list(out_axes_leaves)))),\n\u001b[1;32m   1646\u001b[0m         closure=(tuple(out_axes_leaves), out_axes_treedef))\n\u001b[0;32m-> 1647\u001b[0;31m     out = pxla.xla_pmap(\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m         \u001b[0maxis_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_axis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_axis_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'in_axes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       params_tuple, out_axes_transforms)\n\u001b[1;32m   1550\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/interpreters/pxla.py\u001b[0m in \u001b[0;36mxla_pmap_impl\u001b[0;34m(fun, backend, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, global_arg_shapes, *args)\u001b[0m\n\u001b[1;32m    635\u001b[0m                           \u001b[0;34m(\u001b[0m\u001b[0;34m\"abstract args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                           (\"fingerprint\", fingerprint))\n\u001b[0;32m--> 637\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/interpreters/pxla.py\u001b[0m in \u001b[0;36mexecute_replicated\u001b[0;34m(compiled, backend, in_handler, out_handler, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_replicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_sharded_on_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbufs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = eval_epoch(state, val_dataset, logger, args, best_acc=jnp.array(0.))\n",
    "for epoch in range(args.max_epochs):\n",
    "    state, drp_rng = train_epoch(state, tr_dataset, logger, args, drp_rng)\n",
    "    best_acc = eval_epoch(state, val_dataset, logger, args, best_acc)\n"
   ]
  }
 ]
}