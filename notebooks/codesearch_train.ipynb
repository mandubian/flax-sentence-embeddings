{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('flax-sentence-embeddings-zVHyP_u9-py3.9': venv)"
  },
  "interpreter": {
   "hash": "4fefb6681ffd05f7a8a0fc21cb824f16da8a96bee455cd07578e426e280af9a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# for training script\n",
    "from dataclasses import dataclass, field, asdict, replace\n",
    "from functools import partial\n",
    "from typing import Callable, List, Union\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax import jax_utils, struct, traverse_util\n",
    "from flax.training import train_state\n",
    "from flax.serialization import to_bytes, from_bytes\n",
    "from flax.training.common_utils import shard\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from trainer.loss.custom import multiple_negatives_ranking_loss\n",
    "\n",
    "\n",
    "import wandb\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, FlaxAutoModel\n",
    "import datasets\n",
    "\n",
    "\n",
    "from trainer.utils.ops import normalize_L2, mean_pooling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingArgs:\n",
    "    model_id: str = \"microsoft/codebert-base\"\n",
    "    max_epochs: int = 2\n",
    "    batch_size_per_device: int = 8\n",
    "    seed: int = 42\n",
    "    lr: float = 2e-5\n",
    "    init_lr: float = 1e-5\n",
    "    warmup_steps: int = 2000\n",
    "    weight_decay: float = 1e-3\n",
    "\n",
    "    input1_maxlen: int = 128\n",
    "    input2_maxlen: int = 128\n",
    "    \n",
    "    logging_steps: int = 20\n",
    "    save_dir: str = \"checkpoints\"\n",
    "\n",
    "    tr_data_files: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"tr.csv\",\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    val_data_files: List[str] = field(\n",
    "        default_factory=lambda: [\n",
    "            \"val.csv\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.batch_size = self.batch_size_per_device * jax.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def scheduler_fn(lr, init_lr, warmup_steps, num_train_steps):\n",
    "    decay_steps = num_train_steps - warmup_steps\n",
    "    warmup_fn = optax.linear_schedule(init_value=init_lr, end_value=lr, transition_steps=warmup_steps)\n",
    "    decay_fn = optax.linear_schedule(init_value=lr, end_value=1e-7, transition_steps=decay_steps)\n",
    "    lr = optax.join_schedules(schedules=[warmup_fn, decay_fn], boundaries=[warmup_steps])\n",
    "    return lr\n",
    "\n",
    "def build_tx_0(lr, init_lr, warmup_steps, num_train_steps, weight_decay):\n",
    "    def weight_decay_mask(params):\n",
    "        params = traverse_util.flatten_dict(params)\n",
    "        mask = {k: (v[-1] != \"bias\" and v[-2:] != (\"LayerNorm\", \"scale\")) for k, v in params.items()}\n",
    "        return traverse_util.unflatten_dict(mask)\n",
    "    lr = scheduler_fn(lr, init_lr, warmup_steps, num_train_steps)\n",
    "    tx = optax.adamw(learning_rate=lr, weight_decay=weight_decay, mask=weight_decay_mask)\n",
    "    return tx, lr\n",
    "\n",
    "def warmup_and_constant(lr, init_lr, warmup_steps):\n",
    "    warmup_fn = optax.linear_schedule(init_value=init_lr, end_value=lr, transition_steps=warmup_steps)\n",
    "    constant_fn = optax.constant_schedule(value=lr)\n",
    "    lr = optax.join_schedules(schedules=[warmup_fn, constant_fn], boundaries=[warmup_steps])\n",
    "    return lr\n",
    "\n",
    "def build_tx(lr, init_lr, warmup_steps, weight_decay):\n",
    "    def weight_decay_mask(params):\n",
    "        params = traverse_util.flatten_dict(params)\n",
    "        mask = {k: (v[-1] != \"bias\" and v[-2:] != (\"LayerNorm\", \"scale\")) for k, v in params.items()}\n",
    "        return traverse_util.unflatten_dict(mask)\n",
    "    lr = warmup_and_constant(lr, init_lr, warmup_steps)\n",
    "    tx = optax.adamw(learning_rate=lr, weight_decay=weight_decay, mask=weight_decay_mask)\n",
    "    return tx, lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    loss_fn: Callable = struct.field(pytree_node=False)\n",
    "    scheduler_fn: Callable = struct.field(pytree_node=False)\n",
    "\n",
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def train_step(state, model_input1, model_input2, drp_rng):\n",
    "    train = True\n",
    "    new_drp_rng, drp_rng = jax.random.split(drp_rng, 2)\n",
    "\n",
    "    def loss_fn(params, model_input1, model_input2, drp_rng):\n",
    "        def _forward(model_input):\n",
    "            attention_mask = model_input[\"attention_mask\"]\n",
    "            model_output = state.apply_fn(**model_input, params=params, train=train, dropout_rng=drp_rng)\n",
    "\n",
    "            embedding = mean_pooling(model_output, attention_mask)\n",
    "            embedding = normalize_L2(embedding)\n",
    "\n",
    "            # gather all the embeddings on same device for calculation loss over global batch\n",
    "            embedding = jax.lax.all_gather(embedding, axis_name=\"batch\")\n",
    "            embedding = jnp.reshape(embedding, (-1, embedding.shape[-1]))\n",
    "\n",
    "            return embedding\n",
    "\n",
    "        embedding1, embedding2 = _forward(model_input1), _forward(model_input2)\n",
    "        return state.loss_fn(embedding1, embedding2)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params, model_input1, model_input2, drp_rng)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "\n",
    "    step = jax.lax.pmean(state.step, axis_name=\"batch\")\n",
    "    metrics = {\"train_loss\": loss, \"lr\": state.scheduler_fn(step)}\n",
    "\n",
    "    return state, metrics, new_drp_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def val_step(state, model_inputs1, model_inputs2):\n",
    "    train = False\n",
    "\n",
    "    def _forward(model_input):\n",
    "        attention_mask = model_input[\"attention_mask\"][..., None]\n",
    "        embedding = state.apply_fn(**model_input, params=state.params, train=train)[0]\n",
    "        attention_mask = jnp.broadcast_to(attention_mask, jnp.shape(embedding))\n",
    "\n",
    "        embedding = embedding * attention_mask\n",
    "        embedding = jnp.mean(embedding, axis=1)\n",
    "\n",
    "        modulus = jnp.sum(jnp.square(embedding), axis=-1, keepdims=True)\n",
    "        embedding = embedding / jnp.maximum(modulus, 1e-12)\n",
    "\n",
    "        # gather all the embeddings on same device for calculation loss over global batch\n",
    "        embedding = jax.lax.all_gather(embedding, axis_name=\"batch\")\n",
    "        embedding = jnp.reshape(embedding, (-1, embedding.shape[-1]))\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    embedding1, embedding2 = _forward(model_inputs1), _forward(model_inputs2)\n",
    "    loss = state.loss_fn(embedding1, embedding2)\n",
    "    return jnp.mean(loss)\n",
    "\n",
    "\n",
    "\n",
    "def get_batched_dataset(dataset, batch_size, seed=None):\n",
    "    if seed is not None:\n",
    "        dataset = dataset.shuffle(seed=seed)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i*batch_size: (i+1)*batch_size]\n",
    "        yield dict(batch)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    tokenizer: Union[PreTrainedTokenizerFast, PreTrainedTokenizer]\n",
    "    input1_maxlen: int = 128\n",
    "    input2_maxlen: int = 128\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # Currently only static padding; TODO: change below for adding dynamic padding support\n",
    "        model_input1 = self.tokenizer(batch[\"docstring\"], return_tensors=\"jax\", max_length=self.input1_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input2 = self.tokenizer(batch[\"code\"], return_tensors=\"jax\", max_length=self.input2_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input1, model_input2 = dict(model_input1), dict(model_input2)\n",
    "        return shard(model_input1), shard(model_input2)\n",
    "\n",
    "\n",
    "def save_checkpoint(save_dir, state, save_fn=None, training_args=None):\n",
    "    print(f\"saving checkpoint in {save_dir}\", end=\" ... \")\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    state = jax_utils.unreplicate(state)\n",
    "\n",
    "    if save_fn is not None:\n",
    "        # saving model in HF fashion\n",
    "        save_fn(save_dir, params=state.params)\n",
    "    else:\n",
    "        path = os.path.join(save_dir, \"flax_model.msgpack\")\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(to_bytes(state.params))\n",
    "\n",
    "    # this will save optimizer states\n",
    "    path = os.path.join(save_dir, \"opt_state.msgpack\")\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(to_bytes(state.opt_state))\n",
    "\n",
    "    if training_args is not None:\n",
    "        path = os.path.join(save_dir, \"training_args.json\")\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(asdict(training_args), f)\n",
    "\n",
    "    print(\"done!!\")\n",
    "\n",
    "\n",
    "def prepare_dataset(args):\n",
    "    # tr_dataset = load_dataset(\"csv\", data_files=args.tr_data_files, split=\"train\")\n",
    "    # val_dataset = load_dataset(\"csv\", data_files=args.val_data_files, split=\"val\")\n",
    "    dataset = datasets.load_dataset(\"csv\", data_files={\n",
    "      \"train\": \"../data/codesearchnet_train.csv.gz\",\n",
    "      \"test\": \"../data/codesearchnet_test.csv.gz\",\n",
    "      \"validation\": \"../data/codesearchnet_validation.csv.gz\"\n",
    "    })\n",
    "\n",
    "    # columns_to_remove = ['repo', 'path', 'func_name', 'original_string', 'sha', 'url', 'partition']\n",
    "    # dataset = dataset.remove_columns(columns_to_remove)\n",
    "\n",
    "    # drop extra batch from the end\n",
    "    for split in dataset:\n",
    "        num_samples = len(dataset[split]) - len(dataset[split]) % args.batch_size\n",
    "        dataset[split] = dataset[split].shuffle(seed=args.seed).select(range(num_samples))\n",
    "\n",
    "    tr_dataset, val_dataset = dataset[\"train\"], dataset[\"validation\"]\n",
    "    return tr_dataset, val_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmandubian\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.33<br/>\n                Syncing run <strong style=\"color:#cdcd00\">comic-feather-18</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/mandubian/code-search-net\" target=\"_blank\">https://wandb.ai/mandubian/code-search-net</a><br/>\n                Run page: <a href=\"https://wandb.ai/mandubian/code-search-net/runs/2keyqiu9\" target=\"_blank\">https://wandb.ai/mandubian/code-search-net/runs/2keyqiu9</a><br/>\n                Run data is saved locally in <code>/home/pascal_voitot/flax-sentence-embeddings/notebooks/wandb/run-20210707_125111-2keyqiu9</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TrainingArgs(model_id='microsoft/codebert-base', max_epochs=2, batch_size_per_device=8, seed=42, lr=2e-05, init_lr=1e-05, warmup_steps=2000, weight_decay=0.001, input1_maxlen=128, input2_maxlen=128, logging_steps=20, save_dir='checkpoints-2keyqiu9', tr_data_files=['tr.csv'], val_data_files=['val.csv'])\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArgs()\n",
    "\n",
    "logger = wandb.init(project=\"code-search-net\", config=asdict(args))\n",
    "\n",
    "logging_dict = dict(logger.config); logging_dict[\"save_dir\"] += f\"-{logger.id}\"\n",
    "args = replace(args, **logging_dict)\n",
    "\n",
    "print(args)\n",
    "#main(args, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/498 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "022ba2aa41c54b7a8e4bff311fa8855b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/499M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5ba07faa77a4392bfcdcc9491daa8d9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "model = FlaxAutoModel.from_pretrained(args.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1f2b7008cdb4c7692920a993978cb77"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8faa8ac31e3b4d2b95f1ffbd4887c5ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8510aa0895fa4950a626276061f1b013"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75626886c38a4ff0ba52a0b0562d3faa"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    input1_maxlen=args.input1_maxlen,\n",
    "    input2_maxlen=args.input2_maxlen,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total 16\ndrwxrwxr-x  3 pascal_voitot pascal_voitot 4096 Jul  7 12:48 .\ndrwxrwxr-x 17 pascal_voitot pascal_voitot 4096 Jul  7 12:39 ..\n-rw-rw-r--  1 pascal_voitot pascal_voitot  875 Jul  7 12:10 codesearch.ipynb\ndrwxrwxr-x  4 pascal_voitot pascal_voitot 4096 Jul  7 12:51 wandb\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-83af4b22d0d2ded6\n",
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0 tables [00:00, ? tables/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cca8b6dc227645589ab76350023095bb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0 tables [00:00, ? tables/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fb0870fa62d4cbcafa6fdd347a3f081"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0 tables [00:00, ? tables/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42f3872e96ea4e3e9fbebc580c0a04b4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset csv downloaded and prepared to /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr_dataset, val_dataset = prepare_dataset(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_args = {\n",
    "    \"lr\": args.lr,\n",
    "    \"init_lr\": args.init_lr,\n",
    "    \"warmup_steps\": args.warmup_steps,\n",
    "    \"weight_decay\": args.weight_decay,\n",
    "}\n",
    "tx, lr = build_tx(**tx_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/pascal_voitot/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/lib/xla_bridge.py:382: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n  warnings.warn(\n/home/pascal_voitot/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/lib/xla_bridge.py:369: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx=tx,\n",
    "    loss_fn=multiple_negatives_ranking_loss,\n",
    "    scheduler_fn=lr,\n",
    ")\n",
    "state = jax_utils.replicate(state)\n",
    "\n",
    "rng = jax.random.PRNGKey(args.seed)\n",
    "drp_rng = jax.random.split(rng, jax.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Running epoch-0:   0%|          | 0/10657 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12bede7eeaa847a9b011a8faf4810e37"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/pascal_voitot/.cache/huggingface/datasets/csv/default-83af4b22d0d2ded6/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23/cache-a55611392cb082bd.arrow\n",
      "{'train_loss': 0.07115189731121063, 'step': 20}\n",
      "{'train_loss': 0.12793439626693726, 'step': 40}\n",
      "{'train_loss': 0.026729723438620567, 'step': 60}\n",
      "{'train_loss': 0.11590759456157684, 'step': 80}\n",
      "{'train_loss': 0.030272899195551872, 'step': 100}\n",
      "{'train_loss': 0.028267743065953255, 'step': 120}\n",
      "{'train_loss': 0.023153021931648254, 'step': 140}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80378/1616285513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Running epoch-{epoch}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrp_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrp_rng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_80378/1592784217.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Currently only static padding; TODO: change below for adding dynamic padding support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmodel_input1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docstring\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput1_maxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mmodel_input2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput2_maxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mmodel_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2308\u001b[0m                 )\n\u001b[1;32m   2309\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   2311\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m         )\n\u001b[1;32m   2494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m   2496\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    383\u001b[0m         )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.max_epochs):\n",
    "    # training step\n",
    "    total = len(tr_dataset) // args.batch_size\n",
    "    batch_iterator = get_batched_dataset(tr_dataset, args.batch_size, seed=epoch)\n",
    "    for i, batch in tqdm(enumerate(batch_iterator), desc=f\"Running epoch-{epoch}\", total=total):\n",
    "        model_input1, model_input2 = data_collator(batch)\n",
    "        state, metrics, drp_rng = train_step(state, model_input1, model_input2, drp_rng)\n",
    "\n",
    "        #print(\"metrics\", metrics)\n",
    "        if (i + 1) % args.logging_steps == 0:\n",
    "            train_loss = jax_utils.unreplicate(metrics[\"train_loss\"]).item()\n",
    "            # tqdm.write(str(dict(train_loss=train_loss, step=i+1)))\n",
    "            logger.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"step\": i + 1,\n",
    "            }, commit=True)\n",
    "\n",
    "    # evaluation\n",
    "    val_loss  = jnp.array(0.)\n",
    "    total = len(val_dataset) // args.batch_size\n",
    "    val_batch_iterator = get_batched_dataset(val_dataset, args.batch_size, seed=None)\n",
    "    for j, batch in tqdm(enumerate(val_batch_iterator), desc=f\"Eval after epoch-{epoch}\", total=total):\n",
    "       model_input1, model_input2 = data_collator(batch)\n",
    "       val_step_loss = val_step(state, model_input1, model_input2)\n",
    "       val_loss += jax_utils.unreplicate(val_step_loss)\n",
    "\n",
    "    val_loss = val_loss.item() / (j + 1)\n",
    "    logger.log({\"val_loss\": val_loss}, commit=True)\n",
    "    \n",
    "    save_dir = args.save_dir + f\"-epoch-{epoch}\"\n",
    "    save_checkpoint(save_dir, state, save_fn=model.save_pretrained, training_args=args)            \n"
   ]
  }
 ]
}