{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('flax-sentence-embeddings-zVHyP_u9-py3.9': venv)"
  },
  "interpreter": {
   "hash": "4fefb6681ffd05f7a8a0fc21cb824f16da8a96bee455cd07578e426e280af9a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, FlaxAutoModel\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from flax.training.common_utils import shard\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# for training script\n",
    "from dataclasses import dataclass, field, asdict, replace\n",
    "from functools import partial\n",
    "from typing import Callable, List, Union\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import jax_utils\n",
    "import faiss\n",
    "from trainer.utils.ops import normalize_L2, cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:absl:Starting the local TPU driver.\n",
      "INFO:absl:Unable to initialize backend 'tpu_driver': Not found: Unable to find driver in registry given worker: local://\n",
      "INFO:absl:Unable to initialize backend 'gpu': Not found: Could not find registered platform with name: \"cuda\". Available platform names are: Interpreter TPU Host\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def batch_accuracy(embeddings_a: jnp.DeviceArray, embeddings_b: jnp.DeviceArray,\n",
    "                   similarity_fct=cos_sim):\n",
    "    \"\"\"\n",
    "\n",
    "    :param embeddings_a:\n",
    "    :param embeddings_b: if passing additional hard negatives, use jnp.concatenate([positives, negatives], axis=0) as input.\n",
    "    :param similarity_fct:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert (len(embeddings_a) <= len(embeddings_b))\n",
    "    scores = similarity_fct(embeddings_a, embeddings_b)\n",
    "    assert scores.shape == (len(embeddings_a), len(embeddings_b))\n",
    "\n",
    "    indices = np.argmax(scores, axis=1)\n",
    "\n",
    "    labels = jnp.arange(len(scores), dtype=jnp.int32)\n",
    "\n",
    "    return np.sum(indices == labels)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-2ad89bbbeda92323\n",
      "WARNING:datasets.builder:Reusing dataset csv (/home/pascal_voitot/.cache/huggingface/datasets/csv/default-2ad89bbbeda92323/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"csv\", data_files={\"test\" : \"../data/codesearchnet_test.csv.gz\"}, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class TrainState(train_state.TrainState):\n",
    "#    loss_fn: Callable = struct.field(pytree_node=False)\n",
    "#    scheduler_fn: Callable = struct.field(pytree_node=False)\n",
    "\n",
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def embedding_step(state, model_inputs1, model_inputs2):\n",
    "    train = False\n",
    "\n",
    "    def _forward(model_input):\n",
    "        attention_mask = model_input[\"attention_mask\"][..., None]\n",
    "        embedding = state.apply_fn(**model_input, params=state.params, train=train)[0]\n",
    "        attention_mask = jnp.broadcast_to(attention_mask, jnp.shape(embedding))\n",
    "\n",
    "        embedding = embedding * attention_mask\n",
    "        embedding = jnp.mean(embedding, axis=1)\n",
    "\n",
    "        modulus = jnp.sum(jnp.square(embedding), axis=-1, keepdims=True)\n",
    "        embedding = embedding / jnp.maximum(modulus, 1e-12)\n",
    "\n",
    "        # gather all the embeddings on same device for calculation loss over global batch\n",
    "        embedding = jax.lax.all_gather(embedding, axis_name=\"batch\")\n",
    "        embedding = jnp.reshape(embedding, (-1, embedding.shape[-1]))\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    embedding1, embedding2 = _forward(model_inputs1), _forward(model_inputs2)\n",
    "    return embedding1, embedding2\n",
    "\n",
    "def get_batched_dataset(dataset, batch_size, seed=None):\n",
    "    if seed is not None:\n",
    "        dataset = dataset.shuffle(seed=seed)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i*batch_size: (i+1)*batch_size]\n",
    "        yield dict(batch)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    tokenizer: Union[PreTrainedTokenizerFast, PreTrainedTokenizer]\n",
    "    input1_maxlen: int = 128\n",
    "    input2_maxlen: int = 128\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # Currently only static padding; TODO: change below for adding dynamic padding support\n",
    "        model_input1 = self.tokenizer(batch[\"docstring\"], return_tensors=\"jax\", max_length=self.input1_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input2 = self.tokenizer(batch[\"code\"], return_tensors=\"jax\", max_length=self.input2_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input1, model_input2 = dict(model_input1), dict(model_input2)\n",
    "        return shard(model_input1), shard(model_input2)\n",
    "        # return model_input1, model_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FlaxAutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "# /home/pascal_voitot/flax-sentence-embeddings/notebooks/checkpoints-2gg8aig1-epoch-1\n",
    "# /home/pascal_voitot/flax-sentence-embeddings/notebooks/checkpoints-2shag1q1-epoch-19\n",
    "# model = FlaxAutoModel.from_pretrained(\"checkpoints-2shag1q1-epoch-19\")\n",
    "# model = FlaxAutoModel.from_pretrained(\"checkpoints-2gg8aig1-epoch-1\")\n",
    "model = FlaxAutoModel.from_pretrained(\"checkpoints-2shag1q1-epoch-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    input1_maxlen=200,\n",
    "    input2_maxlen=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/pascal_voitot/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/lib/xla_bridge.py:382: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "/home/pascal_voitot/.cache/pypoetry/virtualenvs/flax-sentence-embeddings-zVHyP_u9-py3.9/lib/python3.9/site-packages/jax/lib/xla_bridge.py:369: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "Compute: 100%|██████████| 1113/1113 [00:51<00:00, 21.62it/s]accs 0.80162716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from flax.training import train_state\n",
    "from itertools import islice\n",
    "import optax\n",
    "\n",
    "batch_size = 32\n",
    "lr = 2e-5\n",
    "init_lr = 1e-5\n",
    "weight_decay = 1e-3\n",
    "warmup_steps = 2000\n",
    "\n",
    "def build_tx(lr, init_lr, warmup_steps, weight_decay):\n",
    "    tx = optax.adamw(learning_rate=lr, weight_decay=weight_decay, mask=None)\n",
    "    return tx, lr\n",
    "\n",
    "tx, lr = build_tx(lr, init_lr, warmup_steps, weight_decay)\n",
    "\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.__call__,\n",
    "    params=model.params,\n",
    "    tx = tx,\n",
    ")\n",
    "state = jax_utils.replicate(state)\n",
    "\n",
    "total = len(ds) // batch_size\n",
    "batch_iterator = get_batched_dataset(ds, batch_size, seed=None)\n",
    "\n",
    "queries = []\n",
    "codes = []\n",
    "accs = 0\n",
    "for j, batch in tqdm(enumerate(batch_iterator), desc=f\"Compute\", total=total):\n",
    "    model_input1, model_input2 = data_collator(batch)\n",
    "    emb1, emb2 = embedding_step(state, model_input1, model_input2)\n",
    "    emb1 = jax_utils.unreplicate(emb1)\n",
    "    emb2 = jax_utils.unreplicate(emb2)\n",
    "    batch_accs = batch_accuracy(emb1, emb2)\n",
    "    accs += batch_accs\n",
    "    \n",
    "    emb1 = normalize_L2(emb1)\n",
    "    emb2 = normalize_L2(emb2)\n",
    "    queries.append(emb1)\n",
    "    codes.append(emb2)\n",
    "\n",
    "accs = accs / len(ds)\n",
    "print(\"accs\", accs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35616, 768)\n"
     ]
    }
   ],
   "source": [
    "codes_all = np.vstack(codes)\n",
    "print(codes_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35616, 768)\n"
     ]
    }
   ],
   "source": [
    "queries_all = np.vstack(queries)\n",
    "print(queries_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(768) \n",
    "index.add(codes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.        , 0.37059227, 0.40204617, 0.41203886, 0.41510835],\n",
       "        [0.        , 0.47468764, 0.50876725, 0.5183419 , 0.5566749 ],\n",
       "        [0.        , 0.18882029, 0.22639921, 0.28134218, 0.40356898],\n",
       "        [0.        , 0.18882029, 0.3476327 , 0.35966137, 0.40546203],\n",
       "        [0.        , 0.2438789 , 0.28134218, 0.3476327 , 0.42306733]],\n",
       "       dtype=float32),\n",
       " array([[   0, 8123,  930, 5203, 7383],\n",
       "        [   1, 2558,  858, 8013, 2625],\n",
       "        [   2,    3,    5,    4, 6155],\n",
       "        [   3,    2,    4,    5,    6],\n",
       "        [   4,    5,    2,    3, 3953]]))"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "index.search(codes_all[:5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.37171227, 0.46303356, 0.49616933, 0.5314659 , 0.53641033],\n",
       "        [0.49271297, 0.49405432, 0.5368102 , 0.53785354, 0.56322914],\n",
       "        [0.43734407, 0.4489539 , 0.45203575, 0.45804134, 0.5295608 ],\n",
       "        [0.45126903, 0.51035976, 0.5367552 , 0.5540974 , 0.5746402 ],\n",
       "        [0.38083267, 0.38380542, 0.39851576, 0.40150896, 0.40514043],\n",
       "        [0.3196303 , 0.34072146, 0.37374735, 0.38923326, 0.4108275 ],\n",
       "        [0.44508794, 0.48792148, 0.4892619 , 0.5127674 , 0.51469815],\n",
       "        [0.35478595, 0.37368542, 0.3775533 , 0.41385037, 0.4160037 ],\n",
       "        [0.21381612, 0.33927527, 0.41578817, 0.43105626, 0.43165684],\n",
       "        [0.37075606, 0.48533714, 0.5066131 , 0.52010864, 0.52266496]],\n",
       "       dtype=float32),\n",
       " array([[    0,  7382,   930,  5529,  8123],\n",
       "        [21268, 20635, 21087, 22332, 22105],\n",
       "        [   16,  1101,     5,     2,  6294],\n",
       "        [    3,     5,     2,    16,  1101],\n",
       "        [    4,  6303,  1717,     2,     5],\n",
       "        [ 1090,  6303,  6302,  6053,  6524],\n",
       "        [ 3658,  6522,  7277,  5226,  2774],\n",
       "        [ 7571,  7568,     7,  3375,  1227],\n",
       "        [    8,   686,  7014,  8123,  3964],\n",
       "        [    9,    10,  4580,  7595,  4023]]))"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "index.search(queries_all[:10], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Ranking: 100%|██████████| 1113/1113 [01:08<00:00, 16.20it/s]batch_mean_mrr 0.736877162463145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = len(queries_all) // batch_size\n",
    "\n",
    "def get_batches(dataset, batch_size, seed=None):\n",
    "    if seed is not None:\n",
    "        dataset = dataset.shuffle(seed=seed)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i*batch_size: (i+1)*batch_size]\n",
    "        yield batch\n",
    "\n",
    "queries_all_batch_iterator = get_batches(queries_all, batch_size, seed=None)\n",
    "# codes_all_batch_iterator = get_batches(codes_all, batch_size, seed=None)\n",
    "\n",
    "ranks = []\n",
    "\n",
    "for idx, q in tqdm(enumerate(queries_all_batch_iterator), desc=f\"Ranking\", total=total):\n",
    "    indices = np.expand_dims(np.arange(idx * batch_size, (idx + 1) * batch_size), 1)\n",
    "    indices = np.tile(indices, 100)\n",
    "    i, batch_ranks = index.search(q, 100)\n",
    "    rank = np.argwhere(batch_ranks == indices)\n",
    "    \n",
    "    rank = rank[:, 1] + 1\n",
    "    ranks.extend(rank)\n",
    "\n",
    "batch_mean_mrr = np.mean(1.0 / np.array(ranks))\n",
    "print(\"batch_mean_mrr\", batch_mean_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoints-2gg8aig1-epoch-1;0.5015809076269152\n",
    "checkpoints-2shag1q1-epoch-19;0.1958147080015603\n",
    "checkpoints-2shag1q1-epoch-1;0.736877162463145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "35616it [23:09, 25.64it/s]mean_mrr 0.5015806329720339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ONE BY ONE\r\n",
    "\r\n",
    "all_ranks = []\r\n",
    "for idx, q in tqdm(enumerate(queries_all)):\r\n",
    "    q = np.expand_dims(q, 0)\r\n",
    "    i, d = index.search(q, 100)\r\n",
    "    ranks = d[0]\r\n",
    "    rank = np.argwhere(ranks == idx)\r\n",
    "    if rank.size > 0:\r\n",
    "        all_ranks.append(rank.item() + 1)\r\n",
    "# print(all_ranks)\r\n",
    "\r\n",
    "mean_mrr = np.mean(1.0 / np.array(all_ranks))\r\n",
    "print(\"mean_mrr\", mean_mrr)"
   ]
  }
 ]
}