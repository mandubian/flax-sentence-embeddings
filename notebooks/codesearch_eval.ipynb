{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('flax-sentence-embeddings-zVHyP_u9-py3.9': venv)"
  },
  "interpreter": {
   "hash": "4fefb6681ffd05f7a8a0fc21cb824f16da8a96bee455cd07578e426e280af9a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, FlaxAutoModel\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from flax.training.common_utils import shard\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# for training script\n",
    "from dataclasses import dataclass, field, asdict, replace\n",
    "from functools import partial\n",
    "from typing import Callable, List, Union\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import jax_utils\n",
    "import faiss\n",
    "from trainer.utils.ops import normalize_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-2ad89bbbeda92323\n",
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/pascal_voitot/.cache/huggingface/datasets/csv/default-2ad89bbbeda92323/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "0 tables [00:00, ? tables/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59487e28aa8f4b9391639cee957e90a6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset csv downloaded and prepared to /home/pascal_voitot/.cache/huggingface/datasets/csv/default-2ad89bbbeda92323/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"csv\", data_files={\"test\" : \"../data/codesearchnet_test.csv.gz\"}, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class TrainState(train_state.TrainState):\n",
    "#    loss_fn: Callable = struct.field(pytree_node=False)\n",
    "#    scheduler_fn: Callable = struct.field(pytree_node=False)\n",
    "\n",
    "\n",
    "@partial(jax.pmap, axis_name=\"batch\")\n",
    "def embedding_step(model_inputs1, model_inputs2):\n",
    "    train = False\n",
    "\n",
    "    def _forward(model_input):\n",
    "        attention_mask = model_input[\"attention_mask\"][..., None]\n",
    "        embedding = model(**model_input, params=model.params, train=train)[0]\n",
    "        attention_mask = jnp.broadcast_to(attention_mask, jnp.shape(embedding))\n",
    "\n",
    "        embedding = embedding * attention_mask\n",
    "        embedding = jnp.mean(embedding, axis=1)\n",
    "\n",
    "        modulus = jnp.sum(jnp.square(embedding), axis=-1, keepdims=True)\n",
    "        embedding = embedding / jnp.maximum(modulus, 1e-12)\n",
    "\n",
    "        # gather all the embeddings on same device for calculation loss over global batch\n",
    "        embedding = jax.lax.all_gather(embedding, axis_name=\"batch\")\n",
    "        embedding = jnp.reshape(embedding, (-1, embedding.shape[-1]))\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    embedding1, embedding2 = _forward(model_inputs1), _forward(model_inputs2)\n",
    "    return embedding1, embedding2\n",
    "\n",
    "def get_batched_dataset(dataset, batch_size, seed=None):\n",
    "    if seed is not None:\n",
    "        dataset = dataset.shuffle(seed=seed)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i*batch_size: (i+1)*batch_size]\n",
    "        yield dict(batch)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    tokenizer: Union[PreTrainedTokenizerFast, PreTrainedTokenizer]\n",
    "    input1_maxlen: int = 128\n",
    "    input2_maxlen: int = 128\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # Currently only static padding; TODO: change below for adding dynamic padding support\n",
    "        model_input1 = self.tokenizer(batch[\"docstring\"], return_tensors=\"jax\", max_length=self.input1_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input2 = self.tokenizer(batch[\"code\"], return_tensors=\"jax\", max_length=self.input2_maxlen, truncation=True, padding=\"max_length\")\n",
    "        model_input1, model_input2 = dict(model_input1), dict(model_input2)\n",
    "        return shard(model_input1), shard(model_input2)\n",
    "        # return model_input1, model_input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FlaxAutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = FlaxAutoModel.from_pretrained(\"checkpoints-2gg8aig1-epoch-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    input1_maxlen=200,\n",
    "    input2_maxlen=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(768) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32, 128)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "data_collator(next(val_batch_iterator))[0][\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Compute: 100%|██████████| 1113/1113 [00:31<00:00, 35.13it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "from itertools import islice\n",
    "total = len(ds) // batch_size\n",
    "val_batch_iterator = get_batched_dataset(ds, batch_size, seed=None)\n",
    "\n",
    "queries = []\n",
    "codes = []\n",
    "for j, batch in tqdm(enumerate(val_batch_iterator), desc=f\"Compute\", total=total):\n",
    "    model_input1, model_input2 = data_collator(batch)\n",
    "    emb1, emb2 = embedding_step(model_input1, model_input2)\n",
    "    emb1 = jax_utils.unreplicate(emb1)\n",
    "    emb1 = normalize_L2(emb1)\n",
    "\n",
    "    emb2 = jax_utils.unreplicate(emb2)\n",
    "    emb2 = normalize_L2(emb2)\n",
    "    queries.append(emb1)\n",
    "    codes.append(emb2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35616, 768)\n"
     ]
    }
   ],
   "source": [
    "codes_all = np.vstack(codes)\n",
    "print(codes_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35616, 768)\n"
     ]
    }
   ],
   "source": [
    "queries_all = np.vstack(queries)\n",
    "print(queries_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(codes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.        , 0.15305121, 0.1570281 , 0.15887779, 0.16033879],\n",
       "        [0.        , 0.11687908, 0.16540855, 0.17207018, 0.18670824],\n",
       "        [0.        , 0.03636249, 0.07812731, 0.10465132, 0.10556918],\n",
       "        [0.        , 0.03636249, 0.09375702, 0.10378852, 0.11198861],\n",
       "        [0.        , 0.07812731, 0.08444145, 0.09375702, 0.09401216]],\n",
       "       dtype=float32),\n",
       " array([[   0, 8123, 2582,  213, 5665],\n",
       "        [   1, 8013, 7307,  923,  922],\n",
       "        [   2,    3,    4, 2188, 6296],\n",
       "        [   3,    2,    4,  794, 2188],\n",
       "        [   4,    2, 2648,    3, 6052]]))"
      ]
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "source": [
    "index.search(codes_all[:5], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[0.19371068, 0.21425068, 0.23767886, 0.24520345, 0.2534646 ],\n",
       "        [0.22690834, 0.24544305, 0.24942982, 0.25861603, 0.2601923 ],\n",
       "        [0.25210357, 0.2698902 , 0.27462995, 0.2758479 , 0.27776644],\n",
       "        [0.26015598, 0.26120454, 0.26836994, 0.27711028, 0.28397453],\n",
       "        [0.09678011, 0.12610778, 0.13524188, 0.1370242 , 0.14111684],\n",
       "        [0.09203597, 0.10387987, 0.11392431, 0.11646447, 0.1178569 ],\n",
       "        [0.19822818, 0.20245108, 0.21533564, 0.21593082, 0.21958163],\n",
       "        [0.1793623 , 0.18039578, 0.18245962, 0.18963315, 0.197237  ],\n",
       "        [0.1444544 , 0.2306124 , 0.24778871, 0.25728324, 0.2623035 ],\n",
       "        [0.18207812, 0.23218426, 0.23329931, 0.23586027, 0.24060239]],\n",
       "       dtype=float32),\n",
       " array([[  662,     0,  8047,  6118,  7258],\n",
       "        [    1,  3480,  4683, 21365, 20562],\n",
       "        [ 6294,   794,     3,  6155,   185],\n",
       "        [    3,   794,   185,  1149,  7664],\n",
       "        [ 6291,  6297,  7195,  6052,     4],\n",
       "        [ 1090,    16,  6291,  6522,  7313],\n",
       "        [ 4795,  7160,  3251,  4724,  7276],\n",
       "        [    7,  3375,  2494,  5211,  2196],\n",
       "        [    8,  7014,   405,  3964,  7174],\n",
       "        [    9,  2848,  2619,  1420,  3023]]))"
      ]
     },
     "metadata": {},
     "execution_count": 245
    }
   ],
   "source": [
    "index.search(queries_all[:10], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "35616it [23:09, 25.64it/s]mean_mrr 0.5015806329720339\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_ranks = []\n",
    "for idx, q in tqdm(enumerate(queries_all)):\n",
    "    q = np.expand_dims(q, 0)\n",
    "    i, d = index.search(q, 100)\n",
    "    ranks = d[0]\n",
    "    rank = np.argwhere(ranks == idx)\n",
    "    if rank.size > 0:\n",
    "        all_ranks.append(rank.item() + 1)\n",
    "# print(all_ranks)\n",
    "\n",
    "mean_mrr = np.mean(1.0 / np.array(all_ranks))\n",
    "print(\"mean_mrr\", mean_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Compute:   0%|          | 0/1113 [00:00<?, ?it/s](32, 100) (array([0, 2]), array([ 1, 54]))\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_89899/3881389551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ranks\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mranks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print(all_ranks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "total = len(queries_all) // batch_size\n",
    "\n",
    "def get_batches(dataset, batch_size, seed=None):\n",
    "    if seed is not None:\n",
    "        dataset = dataset.shuffle(seed=seed)\n",
    "    for i in range(len(dataset) // batch_size):\n",
    "        batch = dataset[i*batch_size: (i+1)*batch_size]\n",
    "        yield batch\n",
    "\n",
    "queries_all_batch_iterator = get_batches(queries_all, batch_size, seed=None)\n",
    "\n",
    "ranks = []\n",
    "for idx, q in tqdm(enumerate(islice(queries_all_batch_iterator, 2)), desc=f\"Compute\", total=total):\n",
    "    i, batch_ranks = index.search(q, 100)\n",
    "    rank = np.nonzero(batch_ranks == idx)\n",
    "    print(batch_ranks.shape, rank)\n",
    "    if rank.size > 0:\n",
    "        ranks.append(rank.item() + 1)\n",
    "# print(all_ranks)\n",
    "\n",
    "batch_mean_mrr = np.mean(1.0 / np.array(ranks))\n",
    "print(\"batch_mean_mrr\", batch_mean_mrr)"
   ]
  }
 ]
}